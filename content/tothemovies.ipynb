{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**The following code snippet is for instructional use. You'll want to rewrite everything. This was the proof of concept to show that the piece could be done using OpenCV->FFMPEG pipeline without tears. There were previously many tears*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on: http://blog.extramaster.net/2015/07/python-creating-timed-image-slideshow.html\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'600 - 600 - this guy likes words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7d823d02d565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# See: http://blog.extramaster.net/2015/07/python-pil-to-mp4.html for the part below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurrentFrame\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFPS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mblendingDuration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mblend\u001b[1;34m(im1, im2, alpha)\u001b[0m\n\u001b[0;32m   2356\u001b[0m     \u001b[0mim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2357\u001b[0m     \u001b[0mim2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2358\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: images do not match"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "songData = [\n",
    "    [20, u'I swear these words scare me', u'this guy likes words', 'minimix', u'test-images/photo2.jpg'],\n",
    "    [0, u'Nitro Fun', u'Final Boss', 'minimix', u'test-images/photo4.jpg']\n",
    "    ]\n",
    "\n",
    "\n",
    "FPS = 60 # Sets the FPS of the entire video\n",
    "currentFrame = 0 # The animation hasn't moved yet, so we're going to leave it as zero\n",
    "startFrame = 0 # The animation of the \"next\" image starts at \"startFrame\", at most\n",
    "#trailingSeconds = 5 # Sets the amount of time we give our last image (in seconds)\n",
    "#blendingDuration = 3.0 # Sets the amount of time that each transition should last for\n",
    "                       # This could be more dynamic, but for now, a constant transition period is chosen\n",
    "#blendingStart = 10 # Sets the time in which the image starts blending before songFile\n",
    "\n",
    "for i in songData:\n",
    "    i[0] = i[0] * FPS # Makes it so that iterating frame-by-frame will result in properly timed slideshows\n",
    "\n",
    "im1 = Image.open(songData[-1][4]) # Load the image in\n",
    "im2 = im1 # Define a second image to force a global variable to be created\n",
    "\n",
    "current = songData[-1][4] # We're going to let the script know the location of the current image's location\n",
    "previous = current # And this is to force/declare a global variable\n",
    "\n",
    "height, width, layers = np.array(im1).shape # Get some stats on the image file to create the video with\n",
    "FMP4 = cv2.VideoWriter_fourcc('F', 'M', 'P', '4') # Fourcc code for FMP4 codec\n",
    "video = cv2.VideoWriter(\"slideshow.avi\",FMP4,60,(width,height),True)\n",
    "\n",
    "while currentFrame < songData[0][0] * FPS * trailingSeconds: # RHS defines the limit of the slideshow\n",
    "    for i in songData: # Loop through each image timing\n",
    "        if currentFrame >= i[0] - (blendingStart * FPS): # If the image timing happens to be for the\n",
    "                                                         # current image, the continue on...\n",
    "                                                         # (Notice how songData is reversed)\n",
    "                                                         \n",
    "            # The print statement adds some verbosity to the program\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(str(currentFrame) + \" - \" + str(i[0] - (blendingStart * FPS)) + \" - \" + i[2])\n",
    "            if not current == i[4]: # Check if the image file has changed\n",
    "                previous = current # We'd want the transition to start if the file has changed\n",
    "                current = i[4]\n",
    "                startFrame = i[0] - (blendingStart * FPS)\n",
    "\n",
    "                # The two images in question for the blending is loaded in\n",
    "                im1 = Image.open(previous)\n",
    "                im2 = Image.open(current)\n",
    "            break\n",
    "\n",
    "    # See: http://blog.extramaster.net/2015/07/python-pil-to-mp4.html for the part below\n",
    "    diff = Image.blend(im1, im2, min(1.0, (currentFrame - startFrame) / float(FPS) / blendingDuration))\n",
    "    video.write(cv2.cvtColor(np.array(diff), cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    currentFrame += 1 # Next frame\n",
    "\n",
    "# At this point, we'll assume that the slideshow has completed generating, and we want to close everything off to prevent a corrupted output.\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x264 = cv2.VideoWriter_fourcc(*'X264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Here's where it begins for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "with Image.open('test-images/photo1.jpg', mode='r') as im:\n",
    "    width, height = im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rewrite me to extend PIL.Image class because youre a bad programmer\n",
    "from PIL import Image\n",
    "class Img:\n",
    "    source_location = None\n",
    "    source_width = None\n",
    "    source_height = None\n",
    "    source_orientation = None\n",
    "    source_format = None\n",
    "    image = None\n",
    "    \n",
    "    def __init__(self, source_location):\n",
    "        self.source_location = source_location\n",
    "        \n",
    "        # Get Sizes\n",
    "        try:\n",
    "            self.image = Image.open(self.source_location, mode='r')\n",
    "            self.source_width, self.source_height = self.image.size\n",
    "            self.source_format = self.image.format\n",
    "        except:\n",
    "            raise\n",
    "        \n",
    "        # Determine Orientation\n",
    "        if self.source_height == self.source_width:\n",
    "            self.source_orientation = \"square\"\n",
    "        elif self.source_height > self.source_width:\n",
    "            self.source_orientation = \"portrait\"\n",
    "        elif self.source_width > self.source_height:\n",
    "            self.source_orientation = \"landscape\"\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(self.source_location  + \"| Orientation: \" + self.source_orientation +\n",
    "               \" | %d x %d\" %(self.source_width, self.source_height))\n",
    "    \n",
    "    def __unicode__(self):\n",
    "        return(self.source_location)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Screen:\n",
    "    name = None\n",
    "    pixel_width = None\n",
    "    pixel_height = None\n",
    "    physical_width = None\n",
    "    physical_height = None\n",
    "    orientation = None\n",
    "    placement_x = None\n",
    "    placement_y = None\n",
    "    \n",
    "    def __init__(self, name, pixel_width=1280, pixel_height=800, orientation = None):\n",
    "        self.name = name\n",
    "        self.pixel_width = pixel_width\n",
    "        self.pixel_height = pixel_height\n",
    "        if orientation == None:\n",
    "            if pixel_width > pixel_height:\n",
    "                orientation = \"landscape\"\n",
    "            else:\n",
    "                orientation = \"portrait\"\n",
    "        else:\n",
    "            self.orientation = orientation\n",
    "        \n",
    "    \n",
    "    def __unicode__(self):\n",
    "        return(self.name)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(self.name + \" | \" + self.orientation)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a bunch of screens\n",
    "frame = []\n",
    "n = 30\n",
    "\n",
    "for i in range(0,n):\n",
    "    name = str(i)\n",
    "    # direction\n",
    "    or_prob = random.random()\n",
    "    if or_prob > .33:\n",
    "\n",
    "        orientation = \"portrait\"\n",
    "    else:\n",
    "        orientation = \"landscape\"\n",
    "    s = Screen(name, orientation=orientation)\n",
    "    #print(s)\n",
    "    frame.append(s)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['photo1.jpg', 'photo2.jpg', 'photo3.jpg', 'photo4.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('test-images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JPEG'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.source_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from resizeimage import resizeimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Image.open('test-images/photo3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ExifTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3264, 2448)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
